{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "M52QDmyzhh9s"
      },
      "outputs": [],
      "source": [
        "\n",
        "with open('data/ass2.pickle', 'rb') as handle:\n",
        "    data = pd.read_pickle(handle)\n",
        "\n",
        "X_train, y_train = data['train']\n",
        "X_dev, y_dev = data['dev']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Rows: 16280\n",
            "The Classes are: [0 1]\n",
            "Class 0: 12360\n",
            "Class 1: 3920\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(f'Number of Rows: {len(y_train)}')\n",
        "print(f'The Classes are: {np.unique(y_train)}')\n",
        "print(f'Class 0: {np.count_nonzero(y_train == 0)}')\n",
        "print(f'Class 1: {np.count_nonzero(y_train == 1)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the above check we understand that we have a binary classification problem so we will focus on algorithms best suited for binary classification.\n",
        "We can see that the dataset is unbalanced so we will balance it.\n",
        "We can also see that we are dealing with a binary classification problem so we will be using algorithms that are a better fit for this kind of problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lazypredict.Supervised import LazyClassifier\n",
        "\n",
        "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
        "models,predictions = clf.fit(X_train, X_dev, y_train, y_dev)\n",
        "\n",
        "print(models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After running LazyPredict we can focus on the few best algorithms we got from it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Under sampled: 7840\n",
            "Over sampled: 24720\n"
          ]
        }
      ],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "rus = RandomUnderSampler(random_state=42, replacement=True)\n",
        "x_rus, y_rus = rus.fit_resample(X_train, y_train)\n",
        "x_ros, y_ros = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "print(f'Under sampled: {len(y_rus)}')\n",
        "print(f'Over sampled: {len(y_ros)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # import libraries\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.metrics import classification_report\n",
        "# import seaborn as sns\n",
        "\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "# # create pandas df\n",
        "# data_iris = pd.DataFrame(X_train)\n",
        "# y = np.array(y_train)\n",
        "# data_iris['target'] = pd.DataFrame(y.reshape(-1, 1), columns=[\"target\"])\n",
        "# data_iris.head(5)\n",
        "\n",
        "# # check the null values\n",
        "# data_iris.isnull().sum()\n",
        "\n",
        "# # pairplot for distribution\n",
        "# sns.pairplot(data_iris ,hue=\"target\", palette='Set1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fQlDPKCh8sc"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "def preproccess(X_train):\n",
        "    sc = StandardScaler()\n",
        "    X_train = sc.fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the above check we understand that we have a binary classification problem so we will focus on algorithms best suited for binary classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def fit_predict(classifier, X_train, y_train):\n",
        "    scaled_X_train = StandardScaler().fit_transform(X_train)\n",
        "    classifier.fit(scaled_X_train, y_train)\n",
        "\n",
        "    train_score = classifier.score(scaled_X_train, y_train)\n",
        "    dev_score = classifier.score(X_dev, y_dev)\n",
        "    over_fitting = train_score - dev_score\n",
        "\n",
        "    print(f'train score: {round(train_score, 3)} test score {round(dev_score, 3)} overfit {round(over_fitting, 3)}')\n",
        "    return classifier\n",
        "\n",
        "def fit_predict_poly(classifier):\n",
        "    transformed_train = PolynomialFeatures(2).fit_transform(X_train)\n",
        "    transformed_dev = PolynomialFeatures(2).fit_transform(X_dev)\n",
        "    classifier.fit(transformed_train, y_train)\n",
        "\n",
        "    train_score = classifier.score(transformed_train, y_train)\n",
        "    dev_score = classifier.score(transformed_dev, y_dev)\n",
        "    over_fitting = train_score - dev_score\n",
        "\n",
        "    return f'train score: {round(train_score, 3)} test score {round(dev_score, 3)} overfit {round(over_fitting)}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "e0pFVAmciHQs",
        "outputId": "79719013-2ffa-49f6-b49c-886d9ba19525"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "results = {}\n",
        "results['naive bayes'] = fit_predict(GaussianNB())\n",
        "results['logistic regression'] = fit_predict(LogisticRegression(random_state = 0))\n",
        "results['K nearest neighbors'] = fit_predict(KNeighborsClassifier())\n",
        "results['SVM'] = fit_predict(SVC(random_state = 0))\n",
        "results['random forest'] = fit_predict(RandomForestClassifier(random_state = 0))\n",
        "results['histogram gradient boosting'] = fit_predict(HistGradientBoostingClassifier())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "#results['gaussian clasifier'] = fit_predict(GaussianProcessClassifier())\n",
        "results['logistic regression poly'] = fit_predict_poly(LogisticRegression(random_state = 0))\n",
        "print(results['logistic regression poly'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "random_forest_classification.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
