{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "M52QDmyzhh9s"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('data/ass2.pickle', 'rb') as handle:\n",
        "    data = pickle.load(handle)\n",
        "\n",
        "X_train, y_train = data['train']\n",
        "X_dev, y_dev = data['dev']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "print(np.unique(y_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the above check we understand that we have a binary classification problem so we will focus on algorithms best suited for binary classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "9fQlDPKCh8sc"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_dev = sc.transform(X_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "def fit_predict(classifier):\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    train_score = classifier.score(X_train, y_train)\n",
        "    dev_score = classifier.score(X_dev, y_dev)\n",
        "    over_fitting = train_score - dev_score\n",
        "\n",
        "    return f'train score: {round(train_score, 3)} test score {round(dev_score, 3)} overfit {round(over_fitting, 3)}'\n",
        "\n",
        "def fit_predict_poly(classifier):\n",
        "    transformed_train = PolynomialFeatures(2).fit_transform(X_train)\n",
        "    transformed_dev = PolynomialFeatures(2).fit_transform(X_dev)\n",
        "    classifier.fit(transformed_train, y_train)\n",
        "\n",
        "    train_score = classifier.score(transformed_train, y_train)\n",
        "    dev_score = classifier.score(transformed_dev, y_dev)\n",
        "    over_fitting = train_score - dev_score\n",
        "\n",
        "    return f'train score: {round(train_score, 3)} test score {round(dev_score, 3)} overfit {round(over_fitting)}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "e0pFVAmciHQs",
        "outputId": "79719013-2ffa-49f6-b49c-886d9ba19525"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'K nearest neighbors': 'train score: 0.877 test score 0.826 overfit 0.051',\n",
            " 'SVM': 'train score: 0.857 test score 0.845 overfit 0.012',\n",
            " 'histogram gradient boosting': 'train score: 0.893 test score 0.872 overfit '\n",
            "                                '0.021',\n",
            " 'logistic regression': 'train score: 0.825 test score 0.826 overfit -0.001',\n",
            " 'naive bayes': 'train score: 0.799 test score 0.801 overfit -0.002',\n",
            " 'random forest': 'train score: 1.0 test score 0.854 overfit 0.146'}\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "results = {}\n",
        "results['naive bayes'] = fit_predict(GaussianNB())\n",
        "results['logistic regression'] = fit_predict(LogisticRegression(random_state = 0))\n",
        "results['K nearest neighbors'] = fit_predict(KNeighborsClassifier())\n",
        "results['SVM'] = fit_predict(SVC(random_state = 0))\n",
        "results['random forest'] = fit_predict(RandomForestClassifier(random_state = 0))\n",
        "results['histogram gradient boosting'] = fit_predict(HistGradientBoostingClassifier())\n",
        "\n",
        "pprint(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train score: 0.854 test score 0.849 overfit 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ofir.kapustian/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "#results['gaussian clasifier'] = fit_predict(GaussianProcessClassifier())\n",
        "results['logistic regression poly'] = fit_predict_poly(LogisticRegression(random_state = 0))\n",
        "print(results['logistic regression poly'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "random_forest_classification.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
